---
output:
  rmarkdown::html_document:
   highlight: pygments
   toc: true
   toc_depth: 3
   fig_width: 5
vignette: >
  %\VignetteIndexEntry{Effectively using the DelayedArray framework as a user to support the analysis of large datasets}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding[ut8]{inputenc}
---

```{r setup, include = FALSE, cache = FALSE}
knitr::opts_chunk$set(
    comment = "#>",
    collapse = TRUE)
```

# Effectively using the DelayedArray framework as a user to support the analysis of large datasets

BioC 2019: 24-27 June

## Instructors

- Peter Hickey (hickey@wehi.edu.au)

## Workshop description

This workshop gives an introductory overview of the DelayedArray framework, which can be used by Bioconductor packages to support the analysis of large datasets.
A *DelayedArray* is like an ordinary array in R, but allows for the data to be in-memory^[Including space-efficient formats like sparse arrays and run length encoded arrays], on-disk in a file, or even hosted on a remote server.
Participants will learn where they might encounter a *DelayedArray* in the wild while using Bioconductor and help them understand the fundamental concepts underlying the framework.
This workshop will be a mixture of lecture with example code and discussion.
Examples will mostly be drawn from the analysis of single-cell RNA-sequencing data, as well as whole-genome bisulfite sequencing and coverage-based assays like ATAC-seq and ChIP-seq.

### Pre-requesites

- Basic knowledge of R syntax.
- Familiarity with common operations on matrices in R, such as `colSums()` and `colMeans()`.
- Some familiarity with S4 objects may be helpful but is not required.
- Some familiarity with single-cell RNA-sequencing may be helpful but is not required.

### Workshop Participation

Students will be able to run code interactively during the workshop.
There will be opportunities throughout the workshop for questions and discussion.

### _R_ / _Bioconductor_ packages used

**TODO:** Once written, go through material and add here (with links).

- DelayedArray
- HDF5Array
- DelayedMatrixStats
- TENxBrainData

### Time outline

| Activity                                        | Time |
|-------------------------------------------------|------|
| Introductory material                           | 10m  |
| First contact                                   | 40m  |
| Package ecosystem                               | 10m  |
| Real world encounters                           | 20m  |
| Workflow tips for DelayedArray-backed analyses  | 20m  |

### Workshop goals and objectives

#### Learning goals

- Learn of existing packages and functions that *use* the DelayedArray framework.
- Develop a high-level understanding of classes and packages that *implement* the DelayedArray framework.
- Become familiar with the fundamental concepts of delayed operations, block-processing, and realization.
- Reason about potential bottlenecks in algorithms operating on *DelayedArray* objects.
- Reason about parallelisation strategies for algorithms operating on *DelayedArray* objects.

#### Learning objectives

- Identify when an object is a *DelayedArray* or one of its derivatives.
- Be able to recognise when it is useful to use a *DelayedArray* instead of an ordinary array or other array-like data structure.
- Learn how to load and save a DelayedArray-backed object.
- Learn how the 'block size' and 'chunking' of the dataset affect performance when operating on *DelayedArray* objects.
- Take away some miscellaneous tips and tricks I've learnt over the years when working with DelayedArray-backed objects.

## Introductory material (10 mins)

Data from a high-throughput biological assay, such as single-cell RNA-sequencing (scRNA-seq), will often be summarised as a matrix of counts, where rows correspond to features and columns to samples^[Higher-dimensional arrays may be appropriate for some types of assays.].
Within **Bioconductor**, the *SummarizedExperiment* class is the recommended container for such data, offering a rich interface that tightly links assay measurements to data on the features and the samples.

The *SummarizedExperiment* class is used to store rectangular arrays of experimental results (_assays_).
Here, each *assay* is drawn as a matrix but higher-dimensional arrays are also supported.

```{r include = FALSE}
# download current version of SE diagram
se_path <- file.path(tempdir(), "SE.svg")
download.file(
  "https://docs.google.com/feeds/download/drawings/Export?id=1kiC8Qlo1mhSnLDqkGiRNPSo6GWn3C2duBszCFbJCB-g&exportFormat=svg", 
  se_path)
```

`r knitr::include_graphics(se_path)`

Traditionally, the assay data are stored in-memory as an ordinary *array* object^[In R, a *matrix* is just a 2-dimensional *array*]. 
Storing the data in-memory becomes a real pain with the ever-growing size of 'omics datasets.
It is now not uncommon to collect $10,000-100,000,000$ measurements on $100 - 1,000,000$ samples, which would occupy $10-1,000$ gigabytes (GB) if stored in-memory as ordinary R arrays.

### Things DA has enabled (5 mins)

- Nature Neuro
- eGTEx
- 10x analysis on a laptop

## First contact (40 mins)

We will begin with an example using some single-cell RNA-seq data on 1.3 million brain cells from embryonic mice, generated by 10X Genomics.
These data are available in the `r BiocStyle::Biocpkg("TENxBrainData")` Bioconductor package.

```{r, message = FALSE}
library(DelayedArray)
# NOTE: This option is for didactic purposes.
setAutoBPPARAM(SerialParam())

# NOTE: The TENxBrainData package loads and attaches the HDF5Array package, 
#       amongst others.
library(TENxBrainData)

# NOTE: This will download the data and may take a little while on the first 
#       run. The result will be cached, however, so subsequent runs avoid 
#       re-downloading the data.
tenx <- TENxBrainData()
```

Let's take a look at the `tenx` object.

```{r}
tenx
```

The data are stored in a *SingleCellExperiment* object, an extension of the *SummarizedExperiment* class.
With data from 1.3 million cells, this is roughly 100,000-times more samples
than a typical bulk RNA-seq dataset and would occupy 146 GB in-memory if stored as an ordinary *matrix*.

We might expect that interacting with an object containing this many samples would feel sluggist, but this is not the case.
For example, we can efficiently subset the object.

```{r}
# Take a random sample of 1000 genes and 200000 samples
tenx[sample(nrow(tenx), 1000), sample(ncol(tenx), 200000)]
```

Now, this efficiency could all be down to some trickery through the outer *SingleCellExperiment* class.
To make things clearer, we'll extract the `counts` assay.

```{r}
# NOTE: We'll discuss the use of `withDimnames = FALSE` later in the workshop.
tenx_counts <- assay(tenx, "counts", withDimnames = FALSE)
```

Now, let's do something that would ordinarily be a terrible idea, and something that's frustrated me way too many times: let's "accidentally" print out the entire counts matrix.

```{r}
tenx_counts
```

Hallelujah!
Unlike what you may have experienced when printing out a large matrix, this didn't overwhelm the screen with thousands of lines of output nor did it cause the R session to hang indefinitely.
In fact, this gives us a rather pretty printing of the counts matrix^[You may have seen similar pretty printing with other Bioconductor objects such as *GRanges* and *DataFrame* or with the *data.table* and *tbl* extensions to the *data.frame*. I can't say enough how much I appreciate these thoughtful touches when doing interactive data analysis.].
No need for panicked mashing of `Ctrl-c` or `Esc`. 

We can now clearly see that `tenx_counts` is no ordinary *matrix*.
In fact, it is an *HDF5Matrix*, which is a type of *DelayedArray*^[As with a 2-dimensional *array* in base R being commonly known as a *matrix*, a 2-dimensional *DelayedArray* is also known as a *DelayedMatrix* and a 2-dimensional *HDF5Array* is also known as a *HDF5Matrix*.].

```{r}
class(tenx_counts)
is(tenx_counts, "DelayedArray")
```

The data contained in an *HDF5Matrix* is actually stored on disk in a [Hierarchical Data Format (**HDF5**)](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) file.
Consequently, the `tenx_counts` object takes up very little space in memory.

```{r}
print(object.size(tenx_counts), units = "auto")
```

We can learn more about the internals of the `tenx_counts` object using the `seed()` function^[We will revisit the `chunkdim` component of the *HDF5Matrix* object later in the workshop.].

```{r}
seed(tenx_counts)
```

### Three examples of computing on a DelayedArray

We will now play around with computing on the counts matrix.
To make things slightly easier, we will first subset the data to 1000 samples.

```{r}
tenx_counts_subset <- tenx_counts[, 1:1000]
```

#### Library sizes

Firstly, let's compute the library sizes for this subset of samples.
We can do this using `colSums()`.

```{r}
lib_sizes <- colSums(tenx_counts_subset)
summary(lib_sizes)
```

#### Proportion of cells with non-zero expression for each gene

Secondly, suppose we want to know for each gene the proportion of cells with non-zero expression.
We can do this using `rowSums()` in conjunction with some standard R command.

```{r}
prop_non_zero <- rowSums(tenx_counts_subset > 0) /  ncol(tenx_counts_subset)
summary(prop_non_zero)
```

#### Median expression of each gene

Finally, suppose we want to know the median expression of each gene.
Here, we will quantify expression as counts per million (CPM) using library size normalization.

```{r}
cpm <- t(t(1e6 * tenx_counts_subset) / lib_sizes)
cpm
```

We can then compute the median expression of each gene using `DelayedMatrixStats::rowMedians()`.

```{r}
library(DelayedMatrixStats)
median_expression <- rowMedians(cpm)
summary(median_expression)
```

#### Summary

These 3 examples highlight the power of the DelayedArray framework
Recall that the data in these examples live on disk in an HDF5 file, yet we interacted with `tenx_counts_subset` and computed on it much as we would if the data were in-memory as an ordinary matrix.
Also note that all 3 examples returned ordinary R vectors.

```{r}
class(lib_sizes)
class(prop_non_zero)
class(cpm)
```

To do so, we made (implicit) use of the three fundamental concepts of the DelayedArray framework:

1. Delayed operations
2. Block-processing
3. Realization

We'll now discuss each of these in turn.

### Delayed operations

Taking a careful look at `tenx_counts_subset`, we see that it is a *DelayedMatrix* rather than an *HDF5Matrix*.

```{r}
tenx_counts_subset
```

The subsetting operation has 'degraded' the `tenx_counts_subset` object to a *DelayedMatrix*.

```{r}
is(tenx_counts_subset, "HDF5Matrix")
is(tenx_counts_subset, "DelayedMatrix")
```

The `showtree()` function can help us see what changed.

```{r}
showtree(tenx_counts)
showtree(tenx_counts_subset)
```

The subsetting operation has been registered in what is termed a 'delayed operation'.
Registering a delayed operation does not modify the underlying data.
Instead, the operation is recorded and only performed when the *DelayedArray* object is 'realized'.
Realization of a *DelayedArray* triggers the execution of the delayed operations carried by the object and returns the result as an ordinary *array*.

This allows us to chain together multiple operations and only perform them as required.
Here is a contrived example.

```{r}
# Add 1 to every element (a delayed op).
x <- tenx_counts_subset + 1L
showtree(x)

# Compute log of every element (another delayed op).
lx <- log(x)
showtree(lx)

# Transpose the result (another delayed op).
tlx <- t(lx)
showtree(tlx)

# Realize a subset of the data as an ordinary matrix.
as.array(tlx[1:5, 1:10])
```

Many common operations can be registered as delayed operations.
Here are some examples^[The technical names of each type of delayed operation are not important.].
Notice that in each case the result is 'degraded' to a *DelayedMatrix*^[The [No-op] example is the obvious exception].

#### DelayedSubset 

```{r}
val <- tenx_counts[, 1:100]
val
showtree(val)
```

#### DelayedAperm

```{r}
val <- t(tenx_counts)
val
showtree(val)
```

#### DelayedUnaryIsoOp

```{r}
val <- tenx_counts + 1L
val
showtree(val)
val <- tenx_counts + 1:2
val
showtree(val)
```

#### DelayedSubassign

```{r}
# NOTE: Be careful with delayed subassignment. You can end up with objects that 
#       are surprisingly large in-memory.
tmp <- tenx_counts
tmp[, 1] <- 100
tmp
showtree(tmp)
```

#### DelayedDimnames

```{r}
tmp <- tenx_counts
rownames(tmp) <- paste0("R", seq_len(nrow(tmp)))
tmp
showtree(tmp)
```

#### DelayedNaryIsoOp

```{r}
val <- tenx_counts + tenx_counts
val
showtree(val)
```

#### DelayedAbind

```{r}
val <- cbind(tenx_counts, tenx_counts)
val
showtree(val)
```

#### No-op

The DelayedArray framework is smart enough to recognise that some combinations of operations are 'no-ops'.

```{r}
val <- t(t(tenx_counts))
val
showtree(val)
```

But it can be fooled.

```{r}
# NOTE: This is a no-op but DelayedArray doesn't recognise it as one.
val <- tenx_counts + 0L
val
showtree(val)
```

### Block-processing

In [Library sizes], we needed to compute the column sums of `tenx_counts_subset`, whose data live on disk in an HDF5 file.
One way of achieving this would be to load the entire dataset into memory as an ordinary matrix and then run `base::colSums()`^[Here, I use the 'namespaced function' notation for didactic purposes to distinguish `base::colSums()` from the S4 generic `colSums()` and its associated methods. When writing code, however, it is generally not necessary to use the `package::function()` notation, except for all the times that it is ...].

```{r}
lib_sizes_in_mem <- colSums(as.array(tenx_counts_subset))
# Check we get the same result as before.
identical(lib_sizes_in_mem, lib_sizes)
```

Here the data at `r print(object.size(as.array(tenx_counts_subset)), units = "auto")` are small enough to load into memory, but what if that's not the case^[For example, recall that the `tenx_counts` data would occupy > 146 GB in memory.]?
One way you might think to do this is to loop over the columns of the matrix, load that column into memory, and compute it's sum^[In the following code example we could replace `as.array(colSums(tenx_counts_subset[, j, drop = FALSE]))` with `sum(tenx_counts_subset[, j, drop = TRUE])` or, more simply, `sum(tenx_counts_subset[, j])`. This is because subsetting a *DelayedArray* returns an ordinary vector when `drop = TRUE` and the result has only one dimension; see 'Subsetting' in `help("DelayedArray", package = "DelayedArray")`.]

```{r}
lib_sizes_loop_over_cols <- vector("numeric", ncol(tenx_counts_subset))
for (j in seq_len(ncol(tenx_counts_subset))) {
  # A simple progress report.
  if (j %% 100 == 0) message("Processed ", j, "/", ncol(tenx_counts_subset))
  lib_sizes_loop_over_cols[j] <- colSums(
    as.array(tenx_counts_subset[, j, drop = FALSE]))
}
# Check we get the same result as before.
identical(lib_sizes_loop_over_cols, lib_sizes)
```

But what if you can't load even a single column into memory^[This may seem artificial, but suppose we were dealing with a very 'tall' matrix.]?
We might loop over the columns of the matrix, partition each column, load each partition, compute its sum, and then compute the sum of the partition sums.

```{r}
# NOTE: Here we will partition each column into two equal-sized subsets.
lib_sizes_loop_over_cols_subset <- vector("numeric", ncol(tenx_counts_subset))
tmp_colsums <- vector("numeric", 2)
nr <- nrow(tenx_counts_subset)

for (j in seq_len(ncol(tenx_counts_subset))) {
  # A simple progress report.
  if (j %% 100 == 0) message("Processed ", j, "/", ncol(tenx_counts_subset))
  for (i in 1:2) {
    i1 <- (i - 1) * nr / 2 + 1
    i2 <- i * nr / 2
    tmp_colsums[i] <- colSums(
      as.array(tenx_counts_subset[seq(i1, i2), j, drop = FALSE]))
  }
  lib_sizes_loop_over_cols_subset[j] <- sum(tmp_colsums)
}
# Check we get the same result as before.
identical(lib_sizes_loop_over_cols_subset, lib_sizes)
```

Hopefully you can now begin to see the general pattern, a strategy which the `r BiocStyle::Biocpkg("DelayedArray")` package calls 'block-processing':

1. Load a 'block' of the data into memory.
2. Compute a summary statistic.
3. Combine the block-level statistics in an appropriate way to get the final result.

#### Block-processing illustrated

Some examples of block-processing are illustrated in the following figures:

`r knitr::include_graphics(file.path(system.file(package = 'DelayedArrayWorkshop', 'vignettes'), "Slide1.png"))`
`r knitr::include_graphics(file.path(system.file(package = 'DelayedArrayWorkshop', 'vignettes'), "Slide2.png"))`
`r knitr::include_graphics(file.path(system.file(package = 'DelayedArrayWorkshop', 'vignettes'), "Slide3.png"))`
`r knitr::include_graphics(file.path(system.file(package = 'DelayedArrayWorkshop', 'vignettes'), "Slide4.png"))`
`r knitr::include_graphics(file.path(system.file(package = 'DelayedArrayWorkshop', 'vignettes'), "Slide5.png"))`
`r knitr::include_graphics(file.path(system.file(package = 'DelayedArrayWorkshop', 'vignettes'), "Slide6.png"))`
`r knitr::include_graphics(file.path(system.file(package = 'DelayedArrayWorkshop', 'vignettes'), "Slide7.png"))`

#### Block-processed column sums

When we run `colSums(tenx_counts_subset`) we are using a block-processed version of column sums, specifically the `colSums,DelayedMatrix-method` implemented in the `r BiocStyle::Biocpkg("DelayedArray")` package.

```{r}
# Turn on progress reports from DelayedArray's block-processing routines.
DelayedArray:::set_verbose_block_processing(TRUE)
head(colSums(tenx_counts_subset))
```

#### More examples of block-processed operations in `r BiocStyle::Biocpkg("DelayedArray")`

Some of the most useful functions in the `r BiocStyle::Biocpkg("DelayedArray")` package implement common operations on a *DelayedMatrix* using block-processing.
These include the following row and column summarization methods:

- `rowSums()`
- `colSums()`
- `rowMeans()`
- `colMeans()`
- `rowMaxs()`
- `colMaxs()`
- `rowMins()`
- `colMins()`
- `rowRanges()`
- `colRanges()`

Two useful but lesser known functions use block-processing to compute column / row sums of a *DelayedMatrix* based on a grouping variable:

- `rowsum()`
- `colsum()`

```{r}
# Compute separate library sizes for mitochondrial and non-mitochondrial genes.
is_mito <- grepl("^mt-", rowData(tenx)$Symbol)
summary(is_mito)
lib_sizes_grouped <- rowsum(tenx_counts_subset, group = is_mito)
head(t(lib_sizes_grouped))
```

Finally, matrix multiplication is implemented as a block-processed operation.

```{r}
# This is mathematically equivalent to rowSums(tenx_counts_subset).
tenx_counts_subset %*% matrix(1, nrow = ncol(tenx_counts_subset))
```

#### DelayedMatrixStats

We've already seen the `r BiocStyle::Biocpkg("DelayedArray")` package in action back when computing the [Median expression of each gene].
`r BiocStyle::Biocpkg("DelayedMatrixStats")` is a port of the `r BiocStyle::CRANpkg("matrixStats")` package's API for use with *DelayedMatrix* objects.
It provides [more than 70 functions](https://github.com/PeteHaitch/DelayedMatrixStats#api-coverage) that apply to rows and columns of *DelayedMatrix* objects

#### General block-processing

As we have seen, many common block-processing operations on a *DelayedMatrix* have already been implemented in `r BiocStyle::Biocpkg("DelayedArray")` or are provided by `r BiocStyle::Biocpkg("DelayedMatrixStats")`.
Nonetheless, there may be times you need to implement your own algorithm using block-processing.
The documentation on this topic is a little sparse, but some details can be found in `help("block_processing", "DelayedArray")` and `help("ArrayGrid", "DelayedArray")` or by reading the source code of the aforementioned packages.
Briefly, to perform block-processing requires that you:

1. Set up an *ArrayGrid* over your *DelayedArray*. This specifies the 'block' structure that will be traversed when processing the *DelayedArray*.
2. Iterate over the *DelayedArray* via the *ArrayGrid*
  a. Read each block of data into memory as an ordinary array using `read_block()`.
  b. Compute the statistic for that block
3. Appropriately combine the block-level statistics to get your final result.

The `blockApply()` and `blockReduce()` functions can help facilitate steps 1-3 , even incorporating parallelization via the `r BiocStyle::Biocpkg("BiocParallel")` package.

### Realization

To *realize* a *DelayedArray* object is to trigger execution of the delayed operations carried by the object and return the result as an ordinary array,
One way to achieve this is to call `as.array()` on it.

```{r}
tenx_counts_subset_realized <- as.array(tenx_counts_subset)
tenx_counts_subset_realized[1:10, 1:10]
```

However, this realizes the full object at once in memory which could require too much memory if the object is big^[In the above example it's safe because `tenx_counts_subset_realized` only requires `r print(object.size(tenx_counts_subset_realized), units = "auto")` of memory.]
A large *DelayedArray* object is preferrably realized on disk, which is most commonly an HDF5 file.

#### Realizing to an HDF5 file

Realizing to an HDF5 file requires that the `r BiocStyle::Biocpkg("HDF5Array")` package is installed^[The `r BiocStyle::Biocpkg("TENxBrainData")` package depends upon `r BiocStyle::Biocpkg("HDF5Array")`, so it is already installed. If you've been following this workflow then you've also already attached it to the search path by running `library(TENxBrainData)`.]

```{r}
tenx_counts_subset_hdf5 <- writeHDF5Array(tenx_counts_subset)
tenx_counts_subset_hdf5

# Alterntivaly, we could 'coerce' the result to be an HDF5Array.
as(tenx_counts_subset, "HDF5Array")
```

Notice that this process of realization used block-processing, which avoids loading the entire dataset entire memory.
Also notice that the result of realization is here returned as an *HDF5Matrix*, which no longer carries around the delayed operations.

```{r}
class(tenx_counts_subset)
class(tenx_counts_subset_hdf5)

showtree(tenx_counts_subset)
showtree(tenx_counts_subset_hdf5)
```

Used like this, `writeHDF5Array()` and `as(..., "HDF5Array")` will write their results to a file in *HDF5 dump directory*, a dumping ground for automatically created HDF5 datasets.
We can see a log of the operations that have written to the HDF5 dump directory using `showHDF5DumpLog()`.

```{r}
showHDF5DumpLog()
```

Often, however, we will want full control of where and how the data are written to the HDF5 file^[We'll discuss why you might want this in the second half of the workshop.] and the `writeHDF5Array()` function gives you full control over this and more.

```{r}
# Write the data to a user-specified HDF5 file using maximum compression and 
# 'chunking' along the columns.
my_hdf5_file <- tempfile(fileext = ".h5")
tenx_counts_subset_my_file_hdf5 <- writeHDF5Array(
  tenx_counts_subset,
  filepath = my_hdf5_file,
  chunkdim = c(nrow(tenx_counts_subset), 1),
  level = 9)

# Compare `tenx_counts_subset_hdf5` to `tenx_counts_subset_my_file_hdf5`
seed(tenx_counts_subset_hdf5)
seed(tenx_counts_subset_my_file_hdf5)
```

#### Realization backends

We've now seen that we can realize to an HDF5 file.
This is called as the HDF5Array 'realization backend' and is implemented in the `r BiocStyle::Biocpkg("HDF5Array")` package.
There are a few other realization backends to be aware of.

```{r}
supportedRealizationBackends()
```

There is also the `NULL` backend, which means the data are realized in memory as an ordinary *array* and then wrapped in a *DelayedArray*.
This is the default realization backend upon loading/attaching the `r BiocStyle::Biocpkg("DelayedArray")` package.

```{r}
getRealizationBackend()
```

The default realization backend can be altered with `setRealizationBackend()`.

```{r}
setRealizationBackend("HDF5Array")
getRealizationBackend()
setRealizationBackend(NULL)
getRealizationBackend()
```

It can be important to know what your current realization backend is because it will be used implicitly by some functions.
For example, matrix multiplication that involves a *DelayedMatrix* uses the current realization backend.

```{r}
setRealizationBackend("HDF5Array")
tenx_counts_subset %*% matrix(1, nrow = ncol(tenx_counts_subset))

setRealizationBackend(NULL)
tenx_counts_subset %*% matrix(1, nrow = ncol(tenx_counts_subset))
```

#### The `realize()` function

We've seen that we can realize to the HDF5Array backend using `writeHDF5Array(tenx_counts_subset)` and `as(tenx_counts_subset, "HDF5Array")`.
A third way of realizing a *DelayedArray* to an HDF5 file is with the `realize()` function.

```{r}
realize(tenx_counts_subset, BACKEND = "HDF5Array")
```

So why might you use `realize()` instead of these other options?
Because it allows us to easily switch out the realization backend and will defer to the current realization backend if none is supplied.

```{r}
# Realize to the current realization backend.
getRealizationBackend()
realize(tenx_counts_subset)

# Realize as an RleArray.
setRealizationBackend("RleArray")
tenx_counts_subset_rlearray <- realize(tenx_counts_subset)
tenx_counts_subset_rlearray

# Switch back to the default backend.
setRealizationBackend(NULL)
```

This is probably most useful when writing package code so that you can allow the user control over the realization backend.

## Package ecosystem (10 mins)

The DelayedArray framework is, unsurprisingly, implemented in the `r BiocStyle::Biocpkg("DelayedArray")` package.
However, there are several other key packages that are an important part of the broader 'ecosystem'.
More importantly, as a user of Bioconductor software, it is increasingly likely that you will encounter *DelayedArray* objects during a data analysis, especially if you are analysing single-cell data^[In fact, if you use any package that makes use of the *SummarizedExperiment* class, then you will almost certainly load the `r BiocStyle::Biocpkg("DelayedArray")` package during the course of your analysis, whether you know it or not! This is because `r BiocStyle::Biocpkg("SummarizedExperiment")` depends upon `r BiocStyle::Biocpkg("DelayedArray")`.].
THe following table lists packages that depend upon the `r BiocStyle::Biocpkg("DelayedArray")` package.

```{r}
dep_tbl <- BiocPkgTools::buildPkgDependencyDataFrame()
da_dep_tbl <- dep_tbl[dep_tbl$dependency == "DelayedArray", 
                      c("Package", "edgetype")]
da_dep_tbl <- da_dep_tbl[with(da_dep_tbl, order(edgetype, Package)), ]
colnames(da_dep_tbl) <- c("Package", "Dependency Type")
rmarkdown::paged_table(da_dep_tbl)
```

We will briefly highlight some of the key packages in this table, broadly categorising these as 'user-focused'/'user-facing' or 'developer-focused' packages and those that span the spectrum.

### Packages that users and developers should probably know about

#### `r BiocStyle::Biocpkg("DelayedArray")`

Well, duh.
Implements the *DelayedArray* and *RleArray* classes, along with all the fundamentals the enable the delayed operations, block processing, and realization that underpin the DelayedArray framework.

#### `r BiocStyle::Biocpkg("HDF5Array")`

Implements the *HDF5Array* and *TENxMatrix* classes, two convenient and memory-efficient array-like containers for on-disk representation of HDF5 datasets. 
*HDF5Array* is for datasets that use the conventional (i.e. dense) HDF5 representation.
*TENxMatrix* is for datasets that use the HDF5-based sparse matrix representation from 10x Genomics.

#### `r BiocStyle::Biocpkg("VCFArray")` and `r BiocStyle::Biocpkg("GDSArray")`

Implements the *VCFArray* and *GDSArray* classes, types of *DelayedArray*, to represent VCF files and GDS-files in an array-like representation.
VCF and GDS files are widely used to represent genotyping or sequence data.

#### `r BiocStyle::Biocpkg("rhdf5client")` and `r BiocStyle::Biocpkg("restfulSE")`

Provide functions and classes to interface with remote data stores by operating on *SummarizedExperiment*-like objects.
These data are HDF5 files living on a remote server running `h5serv`, a REST-based service for HDF5 data.

### User-focused/user-facing packages

These are the packages that as a user you might directly load/attach with `library()` as part of a data analysis.
Alternatively, these may be loaded/attached as a dependency^[As listed in the `Depends` field of the package `DESCRIPTION` file.] of another package you load/attach as part of an analysis.

#### `r BiocStyle::Biocpkg("DropletUtils")`

Provides a number of utility functions for handling single-cell (RNA-seq) data from droplet technologies such as 10X Genomics.
This includes `read10xCounts()` for data loading from count matrices stored in an HDF5 file.
To do this, it makes use of the *TENxMatrix* class.

#### `r BiocStyle::Biocpkg("LoomExperiment")`

Provides a means to convert from 'loom' files to standard Bioconductor classes and back again.
The [Loom file format](http://linnarssonlab.org/loompy/index.html) uses HDF5 to store experimental data and is used by some tools and labs producing data using single-cell assays.
This includes `import()` for data loading from loom files, which are basically a structured HDF5 file.
To do this, it makes use of the *HDF5Matrix* class.

#### `r BiocStyle::Biocpkg("scater")`

A collection of tools for doing various analyses of single-cell RNA-seq gene expression data, with a focus on quality control and visualization.
These methods work on *DelayedMatrix* objects as well as ordinary *matrix* objects and some sparse matrix objects from the `r BiocStyle::CRANpkg("Matrix")` package.

#### `r BiocStyle::Biocpkg("batchelor")`

Implements a variety of methods for batch correction of single-cell (RNA sequencing) data, such as`multiBatchPCA()` and `fastMNN()`.
These methods work on *DelayedMatrix* objects as well as ordinary *matrix* objects and some sparse matrix objects from the `r BiocStyle::CRANpkg("Matrix")` package.

#### `r BiocStyle::Biocpkg("BiocSingular")`

Implements exact and approximate methods for singular value decomposition and principal components analysis, in a framework that allows them to be easily switched within Bioconductor packages or workflows.
These methods work on *DelayedMatrix* objects as well as ordinary *matrix* objects and some sparse matrix objects from the `r BiocStyle::CRANpkg("Matrix")` package.

#### `r BiocStyle::Biocpkg("mbkmeans")`

Implements the mini-batch k-means algorithm for large datasets, including support for on-disk data representation (i.e. *HDF5Matrix* objects).

#### `r BiocStyle::Biocpkg("bsseq")`

A collection of tools for analyzing and visualizing bisulfite sequencing data.
This was one of the first packages to make use of the DelayedArray framework and it supports these throughout the package.
This was needed in order to store and analyse large non-CpG methylation datasets  (> 300 million loci, hundreds of samples) using HDF5 files.
Disclaimer: I did this re-write of `r BiocStyle::Biocpkg("bsseq")` and learnt a lot along the way.

#### `r BiocStyle::Biocpkg("minfi")`

Tools to analyze & visualize Illumina Infinium methylation arrays.
This doesn't have the same level of support for *DelayedMatrix* objects as `r BiocStyle::Biocpkg("bsseq")`, but perhaps one day.
This is needed in order to store and analyse large methylation datasets (> 850,000 loci, tens of thousands of) using HDF5 files.
Disclaimer: This was the second package, after `r BiocStyle::Biocpkg("bsseq")`, I started to re-write to support the DelayedArray framework.
Here, it is rather more difficult because it is a 'widely' used package and has code from lots of different authors with different styles.

#### `r BiocStyle::Biocpkg("DelayedMatrixStats")`

A port of the `r BiocStyle::CRANpkg("matrixStats")` API for use with *DelayedMatrix* objects.
High-performing functions operating on rows and columns of *DelayedMatrix* objects, e.g. `col` / `rowMedians()`, `col` / `rowRanks()`, and `col` / `rowSds()`.
Functions optimized per data type and for subsetted calculations such that both memory usage and processing time is minimized.
Disclaimer: I wrote this one, too.

### Developer-focused packages

#### `r BiocStyle::Biocpkg("beachmat")`

Provides a consistent C++ class interface for reading from and writing data to a variety of commonly used matrix types.
Ordinary matrices and several sparse/dense `r BiocStyle::CRANpkg("Matrix")` classes are directly supported, third-party S4 classes may be supported by external linkage (such as the *HDF5Matrix* class), while all other matrices are handled by DelayedArray block processing.

## Real world encounters with DelayedArray (20 mins)

We will perform a brief analysis of a peripheral blood mononuclear cell (PBMC) scRNA-seq dataset from 10X Genomics (Zheng et al. 2017) to illustrate a real world analysis that makes use of the DelayedArray framework^[This is adapted from the `r BiocStyle::Biocpkg("simpleSingleCell")` workflow.].

This dataset contains more than 4000 cells, which isn't that large in the grand scheme of things, but does allow us to demonstrate some important concepts in a workshop format.
It has been pre-packaged and is available from the `r BiocStyle::Biocpkg("TENxPBMCData")` package as a *SingleCellExperiment* object with a *HDF5Matrix* in the counts assay.
In order to efficiently analyse this data, we would like to use software that supports the *HDF5Matrix* class via the DelayedArray framework.
Thanks to the tireless efforts of Aaron Lun, this is true of many of the key Bioconductor packages for analysing scRNA-seq data: `r BiocStyle::Biocpkg("DropletUtils")`, `r BiocStyle::Biocpkg("scater")`, `r BiocStyle::Biocpkg("scran")`, and `r BiocStyle::Biocpkg("BiocSingular")`.

#### Loading the data

A typical analysis of a 10x Genomics dataset would start by using the `DropletUtils::read10xCounts()` function to load the output of 10x Genomics' CellRanger software into R.
One of these outputs is an HDF5 file, which `DropletUtils::read10xCounts()` can read and return as an HDF5-backed *DelayedMatrix*.
For this workshop, we'll use one we prepared earlier and simply load the 'filtered' dataset from the `r BiocStyle::Biocpkg("TENxPBMCData")` package. 

```{r}
sce <- TENxPBMCData::TENxPBMCData("pbmc4k")
sce
# NOTE: The counts data are stored in an HDF5 file.
class(assay(sce, withDimnames = FALSE))
```

We'll also switch to use the gene symbols provided by 10x Genomics rather than referring to genes by their Ensembl IDs.

```{r}
library(scater)
rownames(sce) <- uniquifyFeatureNames(
  rowData(sce)$ENSEMBL_ID,
  rowData(sce)$Symbol_TENx)
```

#### Quality control on the cells

After loading the data into R, we compute some quality control metrics of the data using `scater::calculateQCMetrics()`.
Under the hood, this involves computing column sums, comparisons of values, and subsetting of the HDF5-backed count matrix, all seamlessly handled by this function.

```{r}
# NOTE: Need to know which genes are mitochondrial to perform QC.
library(EnsDb.Hsapiens.v86)
location <- mapIds(
  EnsDb.Hsapiens.v86,
  keys = rowData(sce)$ENSEMBL_ID, 
  column = "SEQNAME", 
  keytype = "GENEID")
is_mito <- location == "MT"

library(scater)
sce <- calculateQCMetrics(sce, feature_controls = list(Mito = which(is_mito)))
multiplot(
  plotColData(sce, "log10_total_counts") + 
    ylab("Log-total UMI count"),
  plotColData(sce, "total_features_by_counts") + 
    ylab("Log-total number of expressed features"),
  plotColData(sce, "pct_counts_Mito") +
    ylab("Proportion of reads in mitochondrial genes"),
  cols = 2)

# NOTE: We'll discard cells wit large mitochondrial proportions, using it as a
#       proxy for cell damage.
high_mito <- isOutlier(sce$pct_counts_Mito, nmads = 3, type = "higher")
sce <- sce[, !high_mito]

# TODO: Remove mito outliers
```

### Examining gene expression

We can make a plot of the distribution of the most highly expressed genes using `scater::plotHighestExprs()`.
Under the hood, this involves computing row and column sums of the HDF5-backed count matrix.
Again, this is seamlessly handled by this function.

```{r}
plotHighestExprs(sce)
```

### Normalization

Let's move onto something a little more computationally challenging.
Proper normalization is essential for all analyses of gene expression data.
We apply the deconvolution method of Lun, Bach, and Marioni (2016) to compute size factors for all cells.

For highly heterogeneous datasets, like this sample of PBMCs, it is advisable to perform a rough clustering of the cells to better satisfy the assumptions of this normalization method.
Namely, we want to avoid normalizing together cells with a large number of differentially expressed genes between them.

We will use the `scran::quickCluster()` function to perform a clustering based on the principal component scores generated from the log-expression matrix.
This principal component analysis (PCA) in turn uses an approximate singular value decomposition (SVD) with the augmented implicitly Lanczos bidiagonalization algorithm (**irlba**).
If that all sounds rather complicated, then don't worry: that's the point of this example!
We are able to seamlessly apply these cutting edge techniques to our HDF5-backed data.

```{r}
library(scran)
set.seed(1000)
# TODO: This takes a few minutes; is that a problem?
clusters <- quickCluster(
  sce,
  use.ranks = FALSE, 
  BSPARAM = BiocSingular::IrlbaParam())
table(clusters)
```

Following the clustering, we apply the deconvolution method to compute size factors for all cells (**TODO:** Citation Lun, Bach, and Marioni 2016).
**TODO:** Describe DA operations of this method.

```{r}
sce <- computeSumFactors(sce, min.mean = 0.1, cluster = clusters)
# The size factors are well correlated with library sizes.
plot(sce$total_counts, sizeFactors(sce), log = "xy")
```

### Modellng the mean-variance trend

### Dimensionality reduction

### Summary

### Things to include

- Take a 10x dataset in TENxMatrix format.
  - Have to use HDF5Matrix format (see https://github.com/MarioniLab/DropletUtils/issues/15)

- Feature some of the cools things Aaron has been doing with DA
  - DeferredMatrix
  - LowRankMatrix
  - beachmat
  - Deferred PCA

## Workflow tips for DelayedArray-backed analyses (20 mins)

- Saving and loading DA- and HDF5A-backed objects
- Writing functions that 'consume' DAs
- Avoid subsetting too much
- Avoid random access patterns
- Process, save, analyse
- How block size and chunking affect performance
- Parallelisation strategies that work and suck
- Easy wins when using DA
- Debugging
- `withDimnames = FALSE`
- `rhdf5::h5ls()`


### Block-processing performance

Here, this strategy (the 'load it all into memory' strategy) works and is in fact faster and requires less memory allocated^[Total memory allocated is not the same as peak-memory used. For example, a process could allocate 1000 MB of memory as 100 x 10 MB blocks and have a peak memory usage of 10 MB or in 1 x 1000 MB block and have a peak memory usage of 1000 MB. Often it is peak memory we care about, but this is tricky to measure.] than running `colSums(tenx_counts_subset`)`!

```{r}
bench::mark(
  colSums(as.array(tenx_counts_subset)),
  colSums(tenx_counts_subset),
  min_iterations = 10)
```

```{r, echo = FALSE}
knitr::knit_exit()
```

## Concluding remarks

**TODO:** Necessary?

## TODOs

- [ ] Update block-processing figures because code has changed. 
- [x] Find a 10x dataset in TENxData format
- [ ] Get correct citation for Zheng.

```{r, echo = FALSE, eval = FALSE}
# NOTE: This is a lot of code to generate a graph containing little information.


library(ggraph)
library(magrittr)

# NOTE: Adapted from http://lazappi.id.au/2018/06/exploring-the-sce-verse/.
get_bioc_deps <- function(bpi, pkg, reverse) {
  deps <- bpi %>%
    dplyr::filter(Package == pkg)
  
  if (reverse) {
    deps <- deps %>%
      dplyr::select(
        Depends = dependsOnMe,
        Imports = importsMe,
        Suggests = suggestsMe)
  } else {
    deps <- deps %>%
      dplyr::select(Depends, Imports, Suggests)
  }
  
  deps <- deps %>%
    tidyr::gather(key = "type", value = "package") %>%
    tidyr::separate_rows() %>%
    dplyr::filter(!is.na(package))
  
  if (reverse) {
    deps <- deps %>%
      dplyr::mutate(package2 = pkg) %>%
      dplyr::rename(package1 = package)
  } else {
    deps <- deps %>%
      dplyr::mutate(package1 = pkg) %>%
      dplyr::rename(package2 = package)
  }
  
  deps <- deps %>% 
    dplyr::select(package1, Dependency = type, package2)
}
# NOTE: From http://lazappi.id.au/2018/06/exploring-the-sce-verse/
get_cran_deps <- function(pkg, db, reverse) {
  
  types <- c("Depends", "Imports", "Suggests")
  
  deps <- sapply(types, function(type) {
    deps <- tools::package_dependencies(
      pkg,
      db,
      which = type,
      reverse = reverse)
    c(type = type, package = paste(deps[[1]], collapse = ", "))
  })
  
  deps <- deps %>%
    t() %>%
    dplyr::as_data_frame() %>%
    dplyr::mutate(type = tolower(type)) %>%
    dplyr::filter(package != "") %>%
    tidyr::separate_rows(package)
  
  if (nrow(deps) == 0) {
    return(
      dplyr::tibble(
        package1 = character(),
        Dependency = character(),
        package2 = character()))
  }
  
  if (reverse) {
    deps <- deps %>%
      dplyr::mutate(package2 = pkg) %>%
      dplyr::rename(package1 = package)
  } else {
    deps <- deps %>%
      dplyr::mutate(package1 = pkg) %>%
      dplyr::rename(package2 = package)
  }
  
  deps <- deps %>% dplyr::select(package1, Dependency = type, package2)
}

bpi <- BiocPkgTools::biocPkgList()
db <- available.packages(repos = "http://cran.r-project.org")
bioc_revdeps <- get_bioc_deps(bpi, "DelayedArray", reverse = TRUE)
cran_revdeps <- get_cran_deps("DelayedArray", db, reverse = TRUE)
nodes <- bioc_revdeps %>%
  dplyr::bind_rows(cran_revdeps) %>%
  dplyr::select(-Dependency) %>%
  tidyr::gather(key = id, value = package) %>%
  dplyr::select(-id) %>%
  dplyr::distinct() %>%
  dplyr::mutate(
    repo = dplyr::if_else(package %in% bpi$Package, "Bioconductor", "CRAN"))
edges <- bioc_revdeps %>%
  dplyr::bind_rows(cran_revdeps) %>%
  dplyr::rename(from = package1, to = package2)
graph <- tidygraph::tbl_graph(nodes = nodes, edges = edges)

ggraph(graph, layout = "fr") +
  geom_edge_fan(aes(colour = Dependency), check_overlap = FALSE) +
  geom_node_label(aes(label = package), repel = TRUE) +
  scale_edge_color_brewer(palette = "Dark2") +
  theme_graph() + 
  ggtitle("Packages that depend upon DelayedArray")
```

## OLD STUFF


```{r write10x, echo = FALSE}
# NOTE: We'll need to re-create the process of loading the CellRanger output 
#       into SingleCellExperiment object. To do so, we'll take a subset of the 
#       `tenx` object and write it to disk in the CellRanger HDF5 output format.
#       A reminder: you wouldn't do this in a 'real' data analysis! It's just 
#       to create a dataset for our workshop.].
# TODO: Include this code chunk in the 'appendix'.
tenx_subset <- tenx[, 1:1000]
DropletUtils::write10xCounts(
  path = tenx_path,
  x = counts(tenx_subset),
  gene.id = rowData(tenx_subset)$Ensembl,
  type = "HDF5",
  version = "3")
```

```{r, eval = FALSE, echo = FALSE}
# TODO: This doesn't make an HDF5 file in the CellRanger output format.
library(DropletUtils)
tenx_path <- tempfile("tenx_subset", fileext = ".h5")
pbmc4k <- TENxPBMCData::TENxPBMCData("pbmc4k")
writeTENxMatrix(counts(pbmc4k, withDimnames = FALSE), tenx_path, group = "pbmc4k", verbose = TRUE)
```

```{r, eval = FALSE, echo = FALSE}
# TODO: This doesn't produce a TENxMatrix when loading in with read10xCounts().
#       See https://github.com/MarioniLab/DropletUtils/issues/15.
library(DropletUtils)

tenx_path <- tempfile("tenx_subset", fileext = ".h5")
pbmc4k <- TENxPBMCData::TENxPBMCData("pbmc4k")
write10xCounts(
  path = tenx_path,
  x = counts(pbmc4k, withDimnames = FALSE),
  barcodes = pbmc4k$Barcode,
  gene.id = rowData(pbmc4k)$ENSEMBL_ID,
  type = "HDF5",
  version = "3",
  genome = "matrix")
rhdf5::h5ls(tenx_path)
pbmc4k_colData <- colData(pbmc4k)
```

The `DropletUtils::read10xCounts()` function can load the output of the **CellRanger** software into R.
Here we will use it to load the CellRanger 'filtered' HDF5 output file into a *TENxMatrix* object which is then wrapped up in a *SingleCellExperiment*.

```{r}
sce <- read10xCounts(tenx_path)
# NOTE: We include the sample metadata back in.
colData(sce) <- pbmc4k_colData
sce
```

